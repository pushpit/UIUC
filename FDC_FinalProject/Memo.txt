To,
Director, Data Science Group

From,
Pushpit Saxena
Senior Data Scientist

Date: 12/02/2018

Subject: Data curation and its importance for our business process & success

As a government agency the foremost and sacred responsibility that is bestowed upon us by this great nation of ours is transparency and effective reporting of the crucial data points that our agency collected and provide insights into that data using the analysis techniques that we are best known for. People of this nation look towards us with a belief that as a government oversight agency we will have their backs. Our complaints department serves as an important oversight body over the financial corporations conducting their business in our nation. And we as an oversight agency have an utmost responsibility to provide accurate reports to the general public so that they can make an informed decision and their trust increases more on our agency and administration.

One of the most important thing we do is to provide platform for the users to submit their complaints regarding some of the transactions they have done with any financial institution operating in the country. This database of information is very useful as this provides the overall picture of these institutions and all kinds of problems that are prevailing in the system. The volume of complaints received by our agency are continuously increasing as more and more people have increased trust in our reporting and are feeling empowered to submit their complaints. In order to effectively manage such large volumes of data and process it to provide accurate and informational reports to the public, we have data science as the center pillar of our organization. Data science helps us quickly digest large amount of data and provide insights, which at the end help our editors generate good, timely and trustworthy reports. 

Data science is a complex field, but broadly it has two main components: a) Data curation, and b) Data analytics. Data curation is the one that this memo concerns.

According to the field experts, specifically Prof. Allen Renear of UIUC , "Data curation is concerned with all the aspect of data management in order to create a consistent and efficient data pipeline which will help in generating detailed, reliable and reproducible analysis." With no data curation, there is a high risk of decline in the quality of the analysis which at the end will hurt the reputation and reliability of our agency. Most people are of the thought that, the greatness of a data scientist is wrapped up in building better algorithms. However, data science experts say that building a better algorithm is just like building a super-fast rocket ship. It is good on the assumption that the ship is in the right direction. Nobody is interested in moving faster if they are heading in the wrong direction for analysis but this is what truly happens in many organizations. Data curation plays a crucial role in ensuring that the rocket points in the right direction and have all the fuel in place to propel as fast as it can towards its goal.

Few important things the data curation covers:

1. Organizing and Understanding the data: This according to me is one of the most important aspect of data curation. In this age of IOT, we collect data in wide variety of formats. Even when the type of data format (e.g. XML) is same still the same data collected by different sources can have wildly different DTDs (similar issue can occur in data collected as json/db  etc. Subtle difference in the DTDs, json structure, db-schema can lead to a very different looking end data, for which our data scientists will have to invest time cleaning up and which might lead to wildly different analysis also). One example came to my mind is our recent switch of the systems for managing complaints system. Even though the data coming from the new system was in XML format and contains same data, there were small differences in the DTDs. With our robust data curation pipeline, we have maintained the detailed documentation of the old DTD and have adhered to our provenance guidelines. This helped us in quickly turned around and switch to new data collection system. For our data scientist the process was quick and painless as they were getting the same end data and all of their previous as well as new model worked perfectly fine. Now, without our data curation pipeline, such kind of system switches will take a lot more man-hours.

2. Maintaining the existing data: Data curation also helps in maintaining the existing data in the system, and make the process of incremental data collection seamless as data curation activities focuses on defining the policy of data collection and management. It mandates a necessary level of documentation which leads to better understanding and usability in future. It also encompasses preservation of metadata (e.g. source, authors, format etc.) which ensures complete and continued understanding of the data collected. Along with good storage strategy, this will help in preserving the value of data for future use and allow our data scientist to uncover better insights on legacy data as well or to run their improved models seamlessly on the old datasets as well. 

3. Audit records: Provenance is one of the main activities included in the data curation pipeline. With provenance guidelines system preserve an audit trail of data with information like, the source of the data, different formats of the data, who collected the data, how the data is collected, is there any modification done on raw data (canonicalization, normalization etc), which dataset is used to build which ML model, what kind of ML models are build on the data, what reports the data is part of. The answer to these questions seems trivial, but the real strength of this can be attributed to the fact that this empowered the agency to easily track down each and every data point/insights that it has published or will publish in future which leads to increased transparency & stakeholders confidence at the forefront and also substantially reduce the man-hour spent in digging up this information when questions arises on the agency reports. Also, by maintaining this audit trail of the data, agency can also hope to see improved turnaround for model development and analytics as it will be easier for our data scientists to reuse proven and validated past approaches as stepping stones for new research.

Data curation activities also increase discoverability of the data, streamlines access mechanism, help standardizing workflows around the data, increase interoperability between different departments as with standardized policies and processes it will be easier to share information across, and with central data curation pipeline the agency can implement all the privacy and security checks easily at one place, in fact there are dedicated data curation activities which help in increasing the security of the data systems.

So to conclude, if data curation activities are involved in the procurement, processing and maintenance of the data, our agency will have all the mechanism to support the data that is secure, trustworthy and reusable as well as most of the data scientists can have their valuable time devoted to actual algorithm building and betterment of the machine learning models rather than focusing on improving the data quality in the system. The agency can improve on its commitment to increase transparency and provide the stakeholders with trustworthy and timely reports. As a whole this will increase the trust on the agency which can lead to even better funding for our agency as the law makers will definitely realize the efficient, accurate and detailed oversight that our agency is providing.